import streamlit as st
import pandas as pd
import requests
import hashlib
import time
import numpy as np
from io import StringIO
from datetime import datetime

# =============================
# ë³´ì•ˆ ë° ì„¤ì •
# =============================
CORRECT_PASSWORD_HASH = "130568a3fc17054bfe36db359792c487f3a3debd226942fc2394688a7afe8339"


def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False

    if not st.session_state["password_correct"]:
        pw_input = st.sidebar.text_input("ì ‘ì† ë¹„ë°€ë²ˆí˜¸", type="password", key="pw_input")
        if st.sidebar.button("ë¡œê·¸ì¸", key="login_btn"):
            if pw_input:
                entered_hash = hashlib.sha256(pw_input.encode("utf-8")).hexdigest()
                if entered_hash == CORRECT_PASSWORD_HASH:
                    st.session_state["password_correct"] = True
                    st.rerun()
                else:
                    st.sidebar.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
        return False

    return True


# =============================
# (ì˜µì…˜) ìµœì†Œ ë‚´ì¥ DB (CSV ì—†ì„ ë•Œë„ ì•±ì€ ëœ¨ê²Œ)
# =============================
EMBEDDED_MINI_CSV = """
íšŒì‚¬ëª…,ì¢…ëª©ì½”ë“œ,ì„¹í„°
ì‚¼ì„±ì „ì,005930,ê¸°íƒ€
SKí•˜ì´ë‹‰ìŠ¤,000660,ê¸°íƒ€
NAVER,035420,AI
ë„¤ì´ë²„,035420,AI
ì¹´ì¹´ì˜¤,035720,AI
ì…€íŠ¸ë¦¬ì˜¨,068270,ì˜ì•½í’ˆ
ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤,207940,ì˜ì•½í’ˆ
í˜„ëŒ€ì°¨,005380,ê¸°íƒ€
ê¸°ì•„,000270,ê¸°íƒ€
íœ´ë¦¼ë¡œë´‡,090710,ë¡œë´‡
""".strip()


# =============================
# ì¢…ëª© DB ë¡œë”© (ì™„ì „ ì•ˆì •í˜•)
# - 1ìˆœìœ„: ë ˆí¬ ë‚´ íŒŒì¼ krx_stock_list.csv
# - 2ìˆœìœ„: ì•±ì—ì„œ ì—…ë¡œë“œí•œ CSV (ì„¸ì…˜ ìœ ì§€)
# - 3ìˆœìœ„: ë‚´ì¥ ìµœì†Œ CSV
# =============================
@st.cache_data(ttl=60 * 60 * 24)
def load_stock_db_from_repo(filepath: str = "krx_stock_list.csv") -> pd.DataFrame | None:
    try:
        df = pd.read_csv(filepath)
        return df
    except Exception:
        return None


def normalize_stock_db(df: pd.DataFrame) -> pd.DataFrame:
    """
    ìš”êµ¬ ì»¬ëŸ¼: íšŒì‚¬ëª…, ì¢…ëª©ì½”ë“œ, (ì„ íƒ) ì„¹í„°
    """
    df = df.copy()

    # ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª…ì„ í—ˆìš©í•˜ê³  í‘œì¤€í™”
    col_map = {}
    lower_cols = {c.lower(): c for c in df.columns}

    # íšŒì‚¬ëª… í›„ë³´
    for cand in ["íšŒì‚¬ëª…", "name", "corp_name", "company", "companyname"]:
        if cand.lower() in lower_cols:
            col_map[lower_cols[cand.lower()]] = "íšŒì‚¬ëª…"
            break

    # ì¢…ëª©ì½”ë“œ í›„ë³´
    for cand in ["ì¢…ëª©ì½”ë“œ", "code", "symbol", "ticker", "stock_code"]:
        if cand.lower() in lower_cols:
            col_map[lower_cols[cand.lower()]] = "ì¢…ëª©ì½”ë“œ"
            break

    # ì„¹í„° í›„ë³´(ì—†ìœ¼ë©´ ìƒì„±)
    for cand in ["ì„¹í„°", "sector", "ì—…ì¢…", "industry"]:
        if cand.lower() in lower_cols:
            col_map[lower_cols[cand.lower()]] = "ì„¹í„°"
            break

    df = df.rename(columns=col_map)

    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    if "íšŒì‚¬ëª…" not in df.columns or "ì¢…ëª©ì½”ë“œ" not in df.columns:
        raise ValueError("CSVì— 'íšŒì‚¬ëª…'ê³¼ 'ì¢…ëª©ì½”ë“œ' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    if "ì„¹í„°" not in df.columns:
        df["ì„¹í„°"] = "ê¸°íƒ€"

    df["íšŒì‚¬ëª…"] = df["íšŒì‚¬ëª…"].astype(str).str.strip()
    df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.extract(r"(\d+)")[0].fillna(df["ì¢…ëª©ì½”ë“œ"].astype(str))
    df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.zfill(6)
    df["ì„¹í„°"] = df["ì„¹í„°"].astype(str).fillna("ê¸°íƒ€")

    df = df.dropna(subset=["íšŒì‚¬ëª…", "ì¢…ëª©ì½”ë“œ"]).drop_duplicates(subset=["ì¢…ëª©ì½”ë“œ"]).reset_index(drop=True)
    return df


def get_stock_db() -> pd.DataFrame:
    # 1) ì„¸ì…˜ ì—…ë¡œë“œ DB
    if "uploaded_stock_db" in st.session_state and isinstance(st.session_state.uploaded_stock_db, pd.DataFrame):
        try:
            return normalize_stock_db(st.session_state.uploaded_stock_db)
        except Exception:
            pass

    # 2) ë ˆí¬ íŒŒì¼ DB
    repo_df = load_stock_db_from_repo("krx_stock_list.csv")
    if repo_df is not None and not repo_df.empty:
        try:
            return normalize_stock_db(repo_df)
        except Exception:
            pass

    # 3) ë‚´ì¥ ë¯¸ë‹ˆ DB
    df = pd.read_csv(StringIO(EMBEDDED_MINI_CSV))
    return normalize_stock_db(df)


def search_candidates(query: str, limit: int = 20) -> pd.DataFrame:
    df = get_stock_db()
    q = (query or "").strip()
    if not q:
        return df.head(0)

    q2 = q.replace(" ", "").upper()
    name_norm = df["íšŒì‚¬ëª…"].astype(str).str.replace(" ", "", regex=False).str.upper()

    exact = df[name_norm == q2]
    if not exact.empty:
        return exact.head(limit)

    part = df[name_norm.str.contains(q2, na=False)]
    return part.head(limit)


# =============================
# (ì™„ì „ ì•ˆì •í˜•) ì‹œì„¸ ë°ì´í„°: ë¼ì´ë¸Œ + ì—…ë¡œë“œ(ì˜¤í”„ë¼ì¸)
# =============================
def safe_get(url, params=None, headers=None, timeout=10, retries=2, sleep=0.3):
    last_exc = None
    for _ in range(retries + 1):
        try:
            r = requests.get(url, params=params, headers=headers, timeout=timeout)
            r.raise_for_status()
            return r
        except Exception as e:
            last_exc = e
            time.sleep(sleep)
    raise last_exc


def parse_ohlcv_csv(file) -> dict | None:
    """
    ì—…ë¡œë“œ OHLCV CSV ì§€ì›
    ì»¬ëŸ¼ í›„ë³´:
    - date/ë‚ ì§œ
    - open/ì‹œê°€
    - close/ì¢…ê°€
    - volume/ê±°ë˜ëŸ‰
    (í•„ìˆ˜: close, volume)
    """
    try:
        df = pd.read_csv(file)
        print(f"[INFO] Parsing OHLCV CSV: {file.name if hasattr(file, 'name') else 'unknown'}")
        print(f"[INFO] Columns found: {df.columns.tolist()}")

        # ì»¬ëŸ¼ í‘œì¤€í™”
        cols = {c.lower(): c for c in df.columns}
        def pick(*names):
            for n in names:
                if n in cols:
                    return cols[n]
            return None

        c_date = pick("date", "ë‚ ì§œ")
        c_open = pick("open", "ì‹œê°€")
        c_close = pick("close", "ì¢…ê°€")
        c_vol = pick("volume", "ê±°ë˜ëŸ‰")

        if c_close is None or c_vol is None:
            print(f"[ERROR] Missing required columns. Need 'close' and 'volume'")
            return None

        print(f"[INFO] Mapped columns - close: {c_close}, volume: {c_vol}, open: {c_open}, date: {c_date}")

        # ë‚ ì§œ ì •ë ¬(ìˆìœ¼ë©´)
        if c_date is not None:
            df[c_date] = pd.to_datetime(df[c_date], errors="coerce")
            df = df.dropna(subset=[c_date]).sort_values(c_date)

        closes = df[c_close].astype(float).tolist()
        vols = df[c_vol].astype(float).tolist()

        if len(closes) < 35:  # MACD ê³„ì‚° ìµœì†Œ ê¸¸ì´
            print(f"[ERROR] Not enough data rows: {len(closes)} (need at least 35)")
            return None

        current = float(closes[-1])
        prev_close = float(closes[-2])
        volume = float(vols[-1])

        if c_open is not None:
            openp = float(df[c_open].astype(float).iloc[-1])
        else:
            openp = prev_close  # openì´ ì—†ìœ¼ë©´ ëŒ€ì¶© prev_closeë¡œ

        print(f"[SUCCESS] OHLCV parsed successfully. Rows: {len(closes)}, Current: {current}")
        return {
            "current": current,
            "open": openp,
            "prev_close": prev_close,
            "volume": volume,
            "close_prices": closes,
            "volumes": vols,
        }
    except Exception as e:
        print(f"[ERROR] Failed to parse OHLCV CSV: {str(e)}")
        return None


class StockScreener:
    def __init__(self):
        self.headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/120.0.0.0 Safari/537.36"
            ),
            "Referer": "https://finance.naver.com/",
        }

    @st.cache_data(ttl=600)
    def get_stock_data_live(_self, code: str) -> dict | None:
        """
        ë„¤ì´ë²„ ê¸ˆìœµ(ë¼ì´ë¸Œ) - Streamlit Cloudì—ì„œ ë§‰í ìˆ˜ ìˆìŒ
        """
        all_data = []
        try:
            for page in range(1, 4):
                url = "https://finance.naver.com/item/sise_day.naver"
                r = safe_get(url, params={"code": code, "page": page}, headers=_self.headers, timeout=12, retries=1)
                df_list = pd.read_html(r.text)
                if not df_list:
                    break
                df = df_list[0].dropna()
                if df.empty:
                    break
                all_data.append(df)
                time.sleep(0.1)

            if not all_data:
                return None

            combined = pd.concat(all_data, ignore_index=True).sort_values("ë‚ ì§œ").reset_index(drop=True)
            if len(combined) < 35:
                return None

            closes = combined["ì¢…ê°€"].astype(float).tolist()
            vols = combined["ê±°ë˜ëŸ‰"].astype(float).tolist()

            return {
                "current": float(combined.iloc[-1]["ì¢…ê°€"]),
                "open": float(combined.iloc[-1]["ì‹œê°€"]),
                "prev_close": float(combined.iloc[-2]["ì¢…ê°€"]),
                "volume": float(combined.iloc[-1]["ê±°ë˜ëŸ‰"]),
                "close_prices": closes,
                "volumes": vols,
            }
        except Exception as e:
            print(f"[ERROR] Live data fetch failed ({code}): {str(e)}")
            return None

    def get_stock_data(self, code: str) -> dict | None:
        """
        ì™„ì „ ì•ˆì •í˜•:
        1) ì—…ë¡œë“œëœ ì˜¤í”„ë¼ì¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„ 
        2) ì—†ìœ¼ë©´ ë¼ì´ë¸Œ ì‹œë„
        """
        # ì˜¤í”„ë¼ì¸ ë°ì´í„° í™•ì¸ (ë” ëª…í™•í•œ ë¡œê¹…)
        offline_map = st.session_state.get("offline_price_data", {})
        if isinstance(offline_map, dict) and code in offline_map:
            print(f"[INFO] Using offline data: {code}")
            return offline_map[code]

        # ë¼ì´ë¸Œ ì‹œë„
        print(f"[INFO] Attempting live data fetch: {code}")
        live_data = self.get_stock_data_live(code)
        if live_data:
            print(f"[SUCCESS] Live data fetch successful: {code}")
        else:
            print(f"[WARNING] Live data fetch failed: {code}")
        return live_data

    def calculate_rsi(self, prices, period=14):
        if len(prices) < period + 1:
            return None
        s = pd.Series(prices)
        d = s.diff()
        gain = (d.where(d > 0, 0)).rolling(window=period).mean()
        loss = (-d.where(d < 0, 0)).rolling(window=period).mean()
        loss_val = loss.iloc[-1]
        if loss_val == 0:
            return 100.0
        rs = gain.iloc[-1] / loss_val
        return float(100 - (100 / (1 + rs)))

    def calculate_macd(self, prices, fast=12, slow=26, signal=9):
        if len(prices) < slow + signal:
            return None, None, None
        s = pd.Series(prices)
        ema_fast = s.ewm(span=fast, adjust=False).mean()
        ema_slow = s.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        hist = macd_line - signal_line
        return float(macd_line.iloc[-1]), float(signal_line.iloc[-1]), float(hist.iloc[-1])

    def check_macd_crossover(self, prices):
        if len(prices) < 35:
            return None
        s = pd.Series(prices)
        ema_fast = s.ewm(span=12, adjust=False).mean()
        ema_slow = s.ewm(span=26, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=9, adjust=False).mean()
        macd_current = macd_line.iloc[-1]
        macd_prev = macd_line.iloc[-2]
        sig_current = signal_line.iloc[-1]
        sig_prev = signal_line.iloc[-2]

        if macd_prev <= sig_prev and macd_current > sig_current:
            return "ê³¨ë“ í¬ë¡œìŠ¤"
        if macd_prev >= sig_prev and macd_current < sig_current:
            return "ë°ë“œí¬ë¡œìŠ¤"
        return None

    def analyze_stock(self, code, name, sector, data):
        try:
            prices = data["close_prices"]

            rsi = self.calculate_rsi(prices)
            if rsi is None:
                return None

            macd, sig, hist = self.calculate_macd(prices)
            if macd is None:
                return None

            cross = self.check_macd_crossover(prices)
            gap = ((data["open"] - data["prev_close"]) / data["prev_close"]) * 100

            volume_surge = False
            if len(data["volumes"]) >= 5:
                avg_vol = sum(data["volumes"][-5:]) / 5
                if data["volume"] >= avg_vol * 2.0:
                    volume_surge = True

            signals = []
            recommendation = "ê´€ë§"
            rec_color = "ğŸŸ¡"

            if rsi <= 30 and cross == "ê³¨ë“ í¬ë¡œìŠ¤":
                signals.append("â­ ê°•ë ¥ ë§¤ìˆ˜ ì‹ í˜¸ (RSI ê³¼ë§¤ë„ + ê³¨ë“ í¬ë¡œìŠ¤)")
                recommendation = "ì ê·¹ ë§¤ìˆ˜"
                rec_color = "ğŸŸ¢"
            elif rsi <= 30:
                signals.append("RSI ê³¼ë§¤ë„ (ë°˜ë“± ê°€ëŠ¥ì„±)")
                recommendation = "ë§¤ìˆ˜ ê³ ë ¤"
                rec_color = "ğŸŸ¢"
            elif cross == "ê³¨ë“ í¬ë¡œìŠ¤":
                signals.append("MACD ê³¨ë“ í¬ë¡œìŠ¤ (ìƒìŠ¹ ì „í™˜)")
                recommendation = "ë§¤ìˆ˜ ê³ ë ¤"
                rec_color = "ğŸŸ¢"
            elif macd > 0 and rsi < 70:
                signals.append("ìƒìŠ¹ ì¶”ì„¸ ì§€ì† (MACD > 0)")
                recommendation = "ë³´ìœ /ì¶”ê°€ ë§¤ìˆ˜"
                rec_color = "ğŸŸ¢"

            if rsi >= 70:
                signals.append("RSI ê³¼ë§¤ìˆ˜ (ì¡°ì • ê°€ëŠ¥ì„±)")
                recommendation = "ë§¤ë„ ê³ ë ¤"
                rec_color = "ğŸ”´"
            if cross == "ë°ë“œí¬ë¡œìŠ¤":
                signals.append("MACD ë°ë“œí¬ë¡œìŠ¤ (í•˜ë½ ì „í™˜)")
                recommendation = "ë§¤ë„ ê³ ë ¤"
                rec_color = "ğŸ”´"

            if gap < -3:
                signals.append(f"ê°­ í•˜ë½ {gap:.1f}%")
            if volume_surge:
                signals.append("ê±°ë˜ëŸ‰ ê¸‰ì¦ (ìµœê·¼ 5ì¼ í‰ê·  ëŒ€ë¹„ 2ë°°â†‘)")
            if macd > 0:
                signals.append("MACD 0ì„  ìƒë‹¨ (ê°•ì„¸)")

            return {
                "sector": sector,
                "code": code,
                "name": name,
                "current": data["current"],
                "change": ((data["current"] - data["prev_close"]) / data["prev_close"]) * 100,
                "rsi": rsi,
                "macd": macd,
                "signal": sig,
                "macd_cross": cross,
                "gap": gap,
                "volume": data["volume"],
                "signals": signals,
                "recommendation": recommendation,
                "recommendation_color": rec_color,
            }
        except Exception:
            return None

    def check_conditions(self, code, name, sector, data, selected_filters, params):
        try:
            prices = data["close_prices"]

            rsi = self.calculate_rsi(prices)
            if rsi is None:
                return None

            macd, sig, hist = self.calculate_macd(prices)
            if macd is None:
                return None

            cross = self.check_macd_crossover(prices)
            signals = []

            if "RSI ê³¼ë§¤ë„ (30 ì´í•˜)" in selected_filters:
                if rsi > 30:
                    return None
                signals.append("RSI ê³¼ë§¤ë„")

            if "RSI ê³¼ë§¤ìˆ˜ (70 ì´ìƒ)" in selected_filters:
                if rsi < 70:
                    return None
                signals.append("RSI ê³¼ë§¤ìˆ˜")

            if "MACD ê³¨ë“ í¬ë¡œìŠ¤" in selected_filters:
                if cross != "ê³¨ë“ í¬ë¡œìŠ¤":
                    return None
                signals.append("MACD ê³¨ë“ í¬ë¡œìŠ¤")

            if "MACD ë°ë“œí¬ë¡œìŠ¤" in selected_filters:
                if cross != "ë°ë“œí¬ë¡œìŠ¤":
                    return None
                signals.append("MACD ë°ë“œí¬ë¡œìŠ¤")

            if "MACD 0ì„  ëŒíŒŒ" in selected_filters:
                if macd <= 0:
                    return None
                signals.append("MACD 0ì„  ëŒíŒŒ")

            if "RSI ê³¼ë§¤ë„ + MACD ê³¨ë“ í¬ë¡œìŠ¤ (ê°•ë ¥ ë§¤ìˆ˜)" in selected_filters:
                if not (rsi <= 30 and cross == "ê³¨ë“ í¬ë¡œìŠ¤"):
                    return None
                signals.append("â­ ê°•ë ¥ ë§¤ìˆ˜ ì‹ í˜¸")

            if "Gap Down" in selected_filters:
                gap = ((data["open"] - data["prev_close"]) / data["prev_close"]) * 100
                if gap > -params.get("gap_threshold", 5.0):
                    return None
                signals.append(f"ê°­í•˜ë½ {gap:.1f}%")

            if "Volume Surge" in selected_filters:
                if len(data["volumes"]) >= 5:
                    avg_vol = sum(data["volumes"][-5:]) / 5
                    if data["volume"] < avg_vol * params.get("vol_ratio", 2.0):
                        return None
                    signals.append("ê±°ë˜ëŸ‰ ê¸‰ì¦")

            return {
                "ì„¹í„°": sector,
                "ì¢…ëª©ì½”ë“œ": code,
                "ì¢…ëª©ëª…": name,
                "í˜„ì¬ê°€": int(data["current"]),
                "ë“±ë½ìœ¨": f"{round(((data['current'] - data['prev_close']) / data['prev_close']) * 100, 2)}%",
                "RSI": f"{rsi:.1f}",
                "MACD": f"{macd:.2f}",
                "Signal": f"{sig:.2f}",
                "ë§¤ë§¤ì‹ í˜¸": " | ".join(signals) if signals else "-",
                "ê±°ë˜ëŸ‰": int(data["volume"]),
            }
        except Exception:
            return None


# =============================
# UI ë©”ì¸
# =============================
st.set_page_config(page_title="Stock Screener Pro (Cloud Stable)", layout="wide")
st.title("ğŸš€ Stock Screener Pro (Streamlit Cloud ì•ˆì •í˜•)")

if "custom_stocks" not in st.session_state:
    st.session_state.custom_stocks = []

if "offline_price_data" not in st.session_state:
    st.session_state.offline_price_data = {}  # {code: data_dict}


if check_password():
    screener = StockScreener()

    with st.sidebar:
        st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
            st.session_state["password_correct"] = False
            st.rerun()

        st.header("âš™ï¸ í•„í„° ì„¤ì •")
        available_filters = [
            "RSI ê³¼ë§¤ë„ (30 ì´í•˜)",
            "RSI ê³¼ë§¤ìˆ˜ (70 ì´ìƒ)",
            "MACD ê³¨ë“ í¬ë¡œìŠ¤",
            "MACD ë°ë“œí¬ë¡œìŠ¤",
            "MACD 0ì„  ëŒíŒŒ",
            "RSI ê³¼ë§¤ë„ + MACD ê³¨ë“ í¬ë¡œìŠ¤ (ê°•ë ¥ ë§¤ìˆ˜)",
            "Gap Down",
            "Volume Surge",
        ]

        selected_filters = st.multiselect(
            "ì ìš©í•  ìŠ¤í¬ë¦¬ë‹ ì¡°ê±´ì„ ì„ íƒí•˜ì„¸ìš”",
            options=available_filters,
            default=["RSI ê³¼ë§¤ë„ (30 ì´í•˜)"],
            key="selected_filters",
        )

        st.divider()
        st.subheader("ğŸ”§ ì„¸ë¶€ ì„¤ì •")
        params = {}
        if "Gap Down" in selected_filters:
            params["gap_threshold"] = st.slider("ê°­ í•˜ë½ ê¸°ì¤€ (%)", 1.0, 15.0, 5.0, key="gap_threshold")
        if "Volume Surge" in selected_filters:
            params["vol_ratio"] = st.number_input("ê±°ë˜ëŸ‰ ë°°ìˆ˜ (í‰ê·  ëŒ€ë¹„)", 1.0, 10.0, 2.0, key="vol_ratio")

        st.divider()
        st.subheader("ğŸ“Œ ì¢…ëª© DB ì„¸íŒ…(ì¤‘ìš”)")
        st.caption("Streamlit Cloudì—ì„œëŠ” ì™¸ë¶€ í¬ë¡¤ë§ì´ ë§‰í ìˆ˜ ìˆì–´ ì¢…ëª© DBë¥¼ ë¡œì»¬ CSVë¡œ ì“°ëŠ” ê²Œ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.")

        stock_db_file = st.file_uploader(
            "ğŸ“ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ CSV ì—…ë¡œë“œ (íšŒì‚¬ëª…, ì¢…ëª©ì½”ë“œ, ì„¹í„°)",
            type=["csv"],
            key="stock_db_uploader",
        )
        if stock_db_file is not None:
            try:
                df_up = pd.read_csv(stock_db_file)
                st.session_state.uploaded_stock_db = df_up
                st.success("âœ… ì¢…ëª© DB ì—…ë¡œë“œ ì™„ë£Œ! (ì´ ì„¸ì…˜ì—ì„œ ì¦‰ì‹œ ê²€ìƒ‰ì— ë°˜ì˜ë©ë‹ˆë‹¤)")
            except Exception as e:
                st.error("âŒ ì¢…ëª© DB CSV íŒŒì‹± ì‹¤íŒ¨")
                st.write(e)

        st.caption("ë ˆí¬ì— `krx_stock_list.csv` íŒŒì¼ì„ ë„£ì–´ë‘ë©´ ì—…ë¡œë“œ ì—†ì´ë„ í•­ìƒ ë™ì‘í•©ë‹ˆë‹¤.")
        st.divider()

        st.subheader("ğŸ“Œ ì‹œì„¸ ë°ì´í„°(ì˜¤í”„ë¼ì¸) ì—…ë¡œë“œ")
        st.caption("ë¼ì´ë¸Œê°€ ë§‰íˆë©´, ì¢…ëª©ë³„ OHLCV CSV ì—…ë¡œë“œë¡œ ë¶„ì„/ìŠ¤í¬ë¦¬ë‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        st.caption("í•„ìˆ˜ ì»¬ëŸ¼: close(ë˜ëŠ” ì¢…ê°€), volume(ë˜ëŠ” ê±°ë˜ëŸ‰). date/ë‚ ì§œ ìˆìœ¼ë©´ ì •ë ¬ì— ì‚¬ìš©.")

    tab1, tab2, tab3 = st.tabs(["âœï¸ ë‚´ ì¢…ëª© ì¶”ê°€", "â­ ê´€ì‹¬ì¢…ëª© ìŠ¤í¬ë¦¬ë‹", "ğŸ” ê°œë³„ ì¢…ëª© ë¶„ì„"])

    # =========================================================
    # Tab1: ë‚´ ì¢…ëª© ì¶”ê°€
    # =========================================================
    with tab1:
        st.info("ê¸°ì—…ëª…ì„ ê²€ìƒ‰í•´ ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€í•©ë‹ˆë‹¤. (ì¢…ëª© DBëŠ” ë¡œì»¬ CSV ê¸°ë°˜ìœ¼ë¡œ ì•ˆì • ë™ì‘)")

        query = st.text_input("ğŸ” ê¸°ì—…ëª… ì…ë ¥", placeholder="ì˜ˆ: íœ´ë¦¼ë¡œë´‡, ì‚¼ì„±ì „ì", key="add_query")

        if query:
            cands = search_candidates(query, limit=20)

            if cands.empty:
                st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.caption("âœ… í•´ê²°: ì‚¬ì´ë“œë°”ì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ CSV ì—…ë¡œë“œ ë˜ëŠ” ë ˆí¬ì— krx_stock_list.csv ì¶”ê°€")
            else:
                options = [f"{row['íšŒì‚¬ëª…']} ({row['ì¢…ëª©ì½”ë“œ']}) Â· {row.get('ì„¹í„°','ê¸°íƒ€')}" for _, row in cands.iterrows()]
                pick = st.selectbox("âœ… í›„ë³´ ì„ íƒ", options, key="add_pick")
                idx = options.index(pick)

                code = str(cands.iloc[idx]["ì¢…ëª©ì½”ë“œ"]).zfill(6)
                name = str(cands.iloc[idx]["íšŒì‚¬ëª…"])
                sector = str(cands.iloc[idx].get("ì„¹í„°", "ê¸°íƒ€"))

                st.success(f"ì„ íƒë¨: **{name}** ({code})")

                col1, col2 = st.columns(2)

                with col1:
                    if st.button("â• ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€", use_container_width=True, key="add_btn"):
                        if not any(s[0] == code for s in st.session_state.custom_stocks):
                            st.session_state.custom_stocks.append((code, name, sector))
                            st.success("âœ… ì¶”ê°€ ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.warning("âš ï¸ ì´ë¯¸ ì¶”ê°€ëœ ì¢…ëª©ì…ë‹ˆë‹¤.")

                with col2:
                    if st.button("ğŸ“Œ ì§€ê¸ˆ ë°”ë¡œ ë¯¸ë¦¬ ë¶„ì„", use_container_width=True, key="preview_btn"):
                        with st.spinner(f"{name} ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘..."):
                            data = screener.get_stock_data(code)

                        if not data:
                            st.warning("âš ï¸ ë¼ì´ë¸Œ ì‹œì„¸ë¥¼ ëª» ê°€ì ¸ì™”ìŠµë‹ˆë‹¤(Cloud ì°¨ë‹¨ ê°€ëŠ¥).")
                            st.info("âœ… ì•„ë˜ì—ì„œ OHLCV CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                            up = st.file_uploader("ğŸ“ ì´ ì¢…ëª© OHLCV CSV ì—…ë¡œë“œ", type=["csv"], key=f"up_{code}")
                            if up is not None:
                                parsed = parse_ohlcv_csv(up)
                                if parsed:
                                    st.session_state.offline_price_data[code] = parsed
                                    st.success("âœ… ì˜¤í”„ë¼ì¸ ì‹œì„¸ ë“±ë¡ ì™„ë£Œ! ë‹¤ì‹œ 'ë¯¸ë¦¬ ë¶„ì„'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                                else:
                                    st.error("âŒ OHLCV CSV í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (close/volume í•„ìˆ˜)")
                        else:
                            analysis = screener.analyze_stock(code, name, sector, data)
                            if not analysis:
                                st.error("ë¶„ì„ ì‹¤íŒ¨(ë°ì´í„° ë¶€ì¡±/ê³„ì‚° ì˜¤ë¥˜)")
                            else:
                                st.divider()
                                st.subheader(f"ğŸ“ˆ {name} ({code}) ë¯¸ë¦¬ ë¶„ì„")

                                m1, m2, m3, m4 = st.columns(4)
                                with m1:
                                    st.metric("í˜„ì¬ê°€", f"{int(analysis['current']):,}ì›")
                                with m2:
                                    change_color = "normal" if analysis["change"] >= 0 else "inverse"
                                    st.metric("ë“±ë½ìœ¨", f"{analysis['change']:.2f}%", delta=f"{analysis['change']:.2f}%", delta_color=change_color)
                                with m3:
                                    st.metric("RSI", f"{analysis['rsi']:.1f}")
                                with m4:
                                    st.metric("ê±°ë˜ëŸ‰", f"{int(analysis['volume']):,}")

                                st.subheader("ğŸ’¡ ë§¤ë§¤ ì¶”ì²œ")
                                r1, r2 = st.columns([1, 3])
                                with r1:
                                    st.markdown(f"## {analysis['recommendation_color']}")
                                with r2:
                                    st.markdown(f"### **{analysis['recommendation']}**")

                                if analysis.get("signals"):
                                    st.subheader("ğŸ¯ ê°ì§€ëœ ì‹ í˜¸")
                                    for s in analysis["signals"]:
                                        st.markdown(f"- {s}")

        st.divider()
        st.subheader("ğŸ“Œ í˜„ì¬ ì¢…ëª© DB ìƒíƒœ")
        db = get_stock_db()
        st.caption(f"í˜„ì¬ ë¡œë“œëœ ì¢…ëª© ìˆ˜: {len(db):,}ê°œ")
        st.dataframe(db.head(30), use_container_width=True)

    # =========================================================
    # Tab2: ê´€ì‹¬ì¢…ëª© ìŠ¤í¬ë¦¬ë‹
    # =========================================================
    with tab2:
        st.info("ê´€ì‹¬ì¢…ëª© ì „ì²´ë¥¼ í•„í„° ì¡°ê±´ìœ¼ë¡œ ìŠ¤í¬ë¦¬ë‹í•©ë‹ˆë‹¤. (ë¼ì´ë¸Œê°€ ë§‰íˆë©´ ê°œë³„ OHLCV ì—…ë¡œë“œ í•„ìš”)")

        if not st.session_state.custom_stocks:
            st.warning("ê´€ì‹¬ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. 'ë‚´ ì¢…ëª© ì¶”ê°€'ì—ì„œ ë¨¼ì € ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            st.subheader(f"â­ ë‚´ ê´€ì‹¬ì¢…ëª© ({len(st.session_state.custom_stocks)}ê°œ)")

            if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", key="delete_all"):
                st.session_state.custom_stocks = []
                st.success("ëª¨ë“  ì¢…ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

            for idx, (code, name, sector) in enumerate(st.session_state.custom_stocks):
                a, b = st.columns([6, 1])
                with a:
                    st.text(f"{idx+1}. {name} ({code}) [{sector}]")
                with b:
                    if st.button("âŒ", key=f"del_{idx}"):
                        st.session_state.custom_stocks.pop(idx)
                        st.rerun()

            st.divider()

            st.subheader("ğŸ“ (ì˜µì…˜) ê´€ì‹¬ì¢…ëª© OHLCV ì—…ë¡œë“œ")
            st.caption("ë¼ì´ë¸Œ ì°¨ë‹¨ ì‹œ, ì—¬ê¸°ì„œ ì—…ë¡œë“œí•´ë‘ë©´ 'ì¼ê´„ ìŠ¤í¬ë¦¬ë‹'ì´ ì•ˆì •ì ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            up_bulk = st.file_uploader("OHLCV CSV ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ(ê° íŒŒì¼ì€ 1ì¢…ëª©)", type=["csv"], accept_multiple_files=True, key="bulk_ohlcv")
            if up_bulk:
                loaded = 0
                for f in up_bulk:
                    parsed = parse_ohlcv_csv(f)
                    if parsed:
                        # íŒŒì¼ëª…ì— ì½”ë“œê°€ í¬í•¨ë˜ë©´ ê·¸ê±¸ ìš°ì„ ìœ¼ë¡œ
                        # ì˜ˆ: 005930.csv / samsung_005930.csv ë“±
                        fname = f.name
                        found = None
                        for (code, _, _) in st.session_state.custom_stocks:
                            if code in fname:
                                found = code
                                break
                        if found:
                            st.session_state.offline_price_data[found] = parsed
                            loaded += 1
                st.success(f"âœ… ì˜¤í”„ë¼ì¸ ì‹œì„¸ ë“±ë¡ ì™„ë£Œ: {loaded}ê°œ (íŒŒì¼ëª…ì— ì¢…ëª©ì½”ë“œê°€ í¬í•¨ëœ ê²½ìš° ìë™ ë§¤ì¹­)")

            st.divider()

            if st.button("ğŸ” ê´€ì‹¬ì¢…ëª© ì¼ê´„ ìŠ¤í¬ë¦¬ë‹", type="primary", key="bulk_screen"):
                results = []
                progress = st.progress(0)
                status = st.empty()

                total = len(st.session_state.custom_stocks)
                for i, (code, name, sector) in enumerate(st.session_state.custom_stocks):
                    status.text(f"ë¶„ì„ ì¤‘: {name} ({i+1}/{total})")
                    data = screener.get_stock_data(code)

                    if data:
                        res = screener.check_conditions(code, name, sector, data, selected_filters, params)
                        if res:
                            results.append(res)
                    else:
                        st.warning(f"âš ï¸ {name} ({code}) ë°ì´í„° ì—†ìŒ (ë¼ì´ë¸Œ ì°¨ë‹¨ ë˜ëŠ” ì—…ë¡œë“œ í•„ìš”)")

                    progress.progress((i + 1) / total)
                    time.sleep(0.1)

                status.empty()
                progress.empty()

                if results:
                    st.success(f"âœ… ì¡°ê±´ì— ë§ëŠ” ì¢…ëª© **{len(results)}ê°œ**ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.dataframe(pd.DataFrame(results), use_container_width=True)
                else:
                    st.warning("âš ï¸ ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (ë˜ëŠ” ì‹œì„¸ ë°ì´í„°ê°€ ì—†ëŠ” ì¢…ëª©ì´ ë§ìŒ)")

    # =========================================================
    # Tab3: ê°œë³„ ì¢…ëª© ë¶„ì„
    # =========================================================
    with tab3:
        st.info("ì¢…ëª©ì„ ê²€ìƒ‰/ì„ íƒ í›„ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ë´…ë‹ˆë‹¤. (ë¼ì´ë¸Œ ë§‰íˆë©´ OHLCV ì—…ë¡œë“œë¡œ 100% ê°€ëŠ¥)")

        query = st.text_input("ğŸ” ë¶„ì„í•  ê¸°ì—…ëª… ì…ë ¥", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, íœ´ë¦¼ë¡œë´‡", key="single_query")

        if query:
            cands = search_candidates(query, limit=20)

            if cands.empty:
                st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.caption("âœ… í•´ê²°: ì‚¬ì´ë“œë°”ì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ CSV ì—…ë¡œë“œ ë˜ëŠ” ë ˆí¬ì— krx_stock_list.csv ì¶”ê°€")
            else:
                opts = [f"{row['íšŒì‚¬ëª…']} ({row['ì¢…ëª©ì½”ë“œ']}) Â· {row.get('ì„¹í„°','ê¸°íƒ€')}" for _, row in cands.iterrows()]
                pick = st.selectbox("âœ… í›„ë³´ ì„ íƒ", opts, key="single_pick")
                idx = opts.index(pick)

                code = str(cands.iloc[idx]["ì¢…ëª©ì½”ë“œ"]).zfill(6)
                name = str(cands.iloc[idx]["íšŒì‚¬ëª…"])
                sector = str(cands.iloc[idx].get("ì„¹í„°", "ê¸°íƒ€"))

                st.success(f"ì„ íƒë¨: **{name}** ({code})")

                st.subheader("ğŸ“ (í•„ìš” ì‹œ) ì´ ì¢…ëª© OHLCV ì—…ë¡œë“œ")
                up_one = st.file_uploader("OHLCV CSV ì—…ë¡œë“œ", type=["csv"], key=f"one_{code}")
                if up_one is not None:
                    parsed = parse_ohlcv_csv(up_one)
                    if parsed:
                        st.session_state.offline_price_data[code] = parsed
                        st.success("âœ… ì˜¤í”„ë¼ì¸ ì‹œì„¸ ë“±ë¡ ì™„ë£Œ! (ì´ì œ ë¶„ì„ ê°€ëŠ¥)")
                    else:
                        st.error("âŒ OHLCV CSV í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (close/volume í•„ìˆ˜)")

                if st.button("ğŸ“Š ìƒì„¸ ë¶„ì„ ì‹œì‘", type="primary", key="start_analysis"):
                    with st.spinner(f"{name} ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘..."):
                        data = screener.get_stock_data(code)

                    if not data:
                        st.error("âš ï¸ ì‹œì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.caption("Streamlit Cloudì—ì„œ ë„¤ì´ë²„/ê±°ë˜ì†Œê°€ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„ì—ì„œ OHLCV CSV ì—…ë¡œë“œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    else:
                        analysis = screener.analyze_stock(code, name, sector, data)

                        if not analysis:
                            st.error("âš ï¸ ë¶„ì„ ì‹¤íŒ¨(ë°ì´í„° ë¶€ì¡±/ê³„ì‚° ì˜¤ë¥˜)")
                        else:
                            st.divider()
                            st.header(f"ğŸ“ˆ {name} ({code}) ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
                            st.caption(f"ì„¹í„°: {sector}")

                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("í˜„ì¬ê°€", f"{int(analysis['current']):,}ì›")
                            with col2:
                                change_color = "normal" if analysis["change"] >= 0 else "inverse"
                                st.metric("ë“±ë½ìœ¨", f"{analysis['change']:.2f}%", delta=f"{analysis['change']:.2f}%", delta_color=change_color)
                            with col3:
                                st.metric("RSI", f"{analysis['rsi']:.1f}")
                            with col4:
                                st.metric("ê±°ë˜ëŸ‰", f"{int(analysis['volume']):,}")

                            st.divider()
                            st.subheader("ğŸ’¡ ë§¤ë§¤ ì¶”ì²œ")
                            r1, r2 = st.columns([1, 3])
                            with r1:
                                st.markdown(f"# {analysis['recommendation_color']}")
                            with r2:
                                st.markdown(f"## **{analysis['recommendation']}**")

                            st.divider()
                            st.subheader("ğŸ“Š ê¸°ìˆ ì  ì§€í‘œ")

                            i1, i2 = st.columns(2)
                            with i1:
                                st.markdown("### RSI")
                                st.progress(int(min(max(analysis["rsi"], 0), 100)))
                                if analysis["rsi"] <= 30:
                                    st.success(f"ğŸŸ¢ RSI {analysis['rsi']:.1f} - ê³¼ë§¤ë„")
                                elif analysis["rsi"] >= 70:
                                    st.error(f"ğŸ”´ RSI {analysis['rsi']:.1f} - ê³¼ë§¤ìˆ˜")
                                else:
                                    st.info(f"ğŸŸ¡ RSI {analysis['rsi']:.1f} - ì¤‘ë¦½")

                            with i2:
                                st.markdown("### MACD")
                                st.write(f"**MACD Line**: {analysis['macd']:.2f}")
                                st.write(f"**Signal Line**: {analysis['signal']:.2f}")

                                if analysis["macd_cross"] == "ê³¨ë“ í¬ë¡œìŠ¤":
                                    st.success("ğŸŸ¢ ê³¨ë“ í¬ë¡œìŠ¤")
                                elif analysis["macd_cross"] == "ë°ë“œí¬ë¡œìŠ¤":
                                    st.error("ğŸ”´ ë°ë“œí¬ë¡œìŠ¤")
                                elif analysis["macd"] > 0:
                                    st.success("ğŸŸ¢ ìƒìŠ¹ ì¶”ì„¸(MACD>0)")
                                else:
                                    st.warning("ğŸŸ¡ í•˜ë½ ì¶”ì„¸(MACD<0)")

                            if analysis.get("signals"):
                                st.divider()
                                st.subheader("ğŸ¯ ê°ì§€ëœ ì‹ í˜¸")
                                for s in analysis["signals"]:
                                    st.markdown(f"- {s}")

else:
    st.info("ğŸ”’ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
